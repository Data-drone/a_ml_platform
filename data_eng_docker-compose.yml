version: '3.7'
services:
  metastore_db:
    image: postgres:10.5
    container_name: metastore_db 
    ports:
      - "5433:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U metastore" ]
      interval: 10s
      timeout: 5s
      retries: 5
    env_file:
      - hivemetastore/config/common.env
    networks: 
      ml_platform: {}
  hive_metastore:
    container_name: hive_metastore
    hostname: hive_metastore
    build:
      context: ./hivemetastore
      dockerfile: Dockerfile
    depends_on:
      metastore_db:
        condition: service_healthy
    ports:
      - "9083:9083"
    env_file:
      - hivemetastore/config/common.env
    networks: 
      ml_platform: {}
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9001:9000"
    volumes:
      - /mnt/38390e7f-c8b3-4b79-8750-eff41b386f03/ml_platform_data:/data 
    environment:
      MINIO_ROOT_USER: AKIAIOSFODNN7EXAMPLE
      MINIO_ROOT_PASSWORD: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
    hostname: minio
    entrypoint: sh
    command: -c 'mkdir -p /data/storage && /usr/bin/minio server /data'  
    networks: 
      ml_platform: {}
  spark-master:
    #image: datadrone/spark-master:3.1.1-hadoop3.2-rapids
    build:
      context: ./spark_ext_metastore
      dockerfile: Dockerfile_Master
    ports:
      - "9080:8080"
      - "7077:7077"
    environment:
      - "SPARK_LOCAL_IP=spark-master"
      - "PYSPARK_PYTHON=/usr/bin/python3"
      - "PYSPARK_DRIVER_PYTHON=/usr/bin/python3"
      - "MINIO_ACCESS_KEY=AKIAIOSFODNN7EXAMPLE"
      - "MINIO_SECRET_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
    networks: 
      ml_platform: {}
  spark-worker-1:
    #image: datadrone/spark-worker:3.1.1-hadoop3.2-rapids
    build:
      context: ./spark_ext_metastore
      dockerfile: Dockerfile_Worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=16
      - SPARK_WORKER_MEMORY=32G
      - SPARK_DRIVER_MEMORY=128m
      - SPARK_EXECUTOR_MEMORY=256m
      - SPARK_WORKER_OPTS=-Dspark.worker.resource.gpu.amount=2 -Dspark.worker.resource.gpu.discoveryScript=/opt/sparkRapidsPlugin/getGpusResources.sh
      - "PYSPARK_PYTHON=/usr/bin/python3"
      - "PYSPARK_DRIVER_PYTHON=/usr/bin/python3"
      - "MINIO_ACCESS_KEY=AKIAIOSFODNN7EXAMPLE"
      - "MINIO_SECRET_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0', '1']
            capabilities: [gpu, utility, compute]
    networks:
      ml_platform: {}
  spark-notebook:
    #image: datadrone/spark_notebook:3.1.1-hadoop3.2
    build:
      context: ./spark_ext_metastore
      dockerfile: Dockerfile_NB
    ports:
      - "9494:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JAVA_HOME=/usr
      - SPARK_MASTER=spark://spark-master:7077
      - "PYSPARK_PYTHON=/usr/bin/python3"
      - "PYSPARK_DRIVER_PYTHON=/usr/bin/python3"
      - "MINIO_ACCESS_KEY=AKIAIOSFODNN7EXAMPLE"
      - "MINIO_SECRET_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
    ipc: host  
    networks:
      ml_platform: {}
networks:
  ml_platform:
    external: false
    name: ml_platform